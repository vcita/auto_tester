# vcita Test Agent - Project Rules

## Overview

This is an AI-driven browser test agent for vcita. It operates as a **black-box tester** - no access to vcita's source code. The agent explores the application like a real user, learns correct behavior, and generates self-healing tests.

## Architecture

### Folder Structure

```
tests/
├── _functions/                  # Global reusable functions
│   ├── _functions.yaml          # Function registry
│   ├── login/
│   │   ├── steps.md
│   │   ├── script.md
│   │   ├── test.py
│   │   └── changelog.md
│   ├── logout/
│   ├── create_client/
│   └── ...
├── booking/                     # Test category
│   ├── _category.yaml           # Category config, test order
│   ├── _setup/                  # Runs before tests (optional)
│   │   ├── steps.md             # Can call functions: "Call: login"
│   │   ├── script.md
│   │   ├── test.py
│   │   └── changelog.md
│   ├── _teardown/               # Runs after tests (optional)
│   │   └── ...
│   ├── create_meeting/          # Test folder
│   │   ├── steps.md
│   │   ├── script.md
│   │   ├── test.py
│   │   └── changelog.md
│   └── recurring/               # Subcategory (independent setup/teardown)
│       ├── _category.yaml
│       ├── _setup/
│       └── setup_weekly/
└── clients/                     # Another category
    └── ...

.context/                        # Runtime context (fresh each run)
└── current_run.json             # Shared data between tests
```

### Three-Phase Document Hierarchy

Every test, function, setup, and teardown consists of three files:

| Phase | File | Description |
|-------|------|-------------|
| 1 | `steps.md` | Human-readable steps (WHAT to do) |
| 2 | `script.md` | Detailed action script (HOW to do it) |
| 3 | `test.py` | Executable Playwright code (IMPLEMENTATION) |

Plus `changelog.md` that logs all changes.

### CRITICAL: Strict Phase Order (NEVER SKIP)

**You MUST create files in strict order: steps.md → script.md → test.py**

1. **NEVER create `test.py` without a complete `script.md`**
   - The script.md contains VERIFIED PLAYWRIGHT CODE from MCP exploration
   - test.py is generated BY COPYING code from script.md
   - Without script.md, you have no verified code to copy

2. **NEVER create `script.md` without a complete `steps.md`**
   - The steps.md defines WHAT the test should do
   - script.md documents HOW to do it (with verified code)
   - Without steps.md, you don't know what to explore

3. **If a test has `test.py` but no `script.md`, it is INVALID**
   - The test.py must be regenerated from a proper script.md
   - First create the script.md by exploring with MCP
   - Then regenerate test.py from the verified code

### Change Flow
- Changes cascade: `steps.md` -> `script.md` -> `test.py`
- When self-healing detects significant flow changes, update all three files
- Every change must be logged in `changelog.md`

## Key Concepts

### 1. Functions (`_functions/`)
- Global reusable actions (login, logout, create_client, etc.)
- Have 3 files + changelog (self-healable like tests)
- Accept simple parameters only
- Called from steps.md with `Call: function_name`

### 2. Setup/Teardown (`_setup/`, `_teardown/`)
- Optional per category/subcategory
- Treated like tests (3 files, self-healable)
- Setup runs before all tests in category
- Teardown runs after all tests (even on failure)
- Subcategories are independent (don't inherit parent's setup)

### 3. Sequential Execution
- Tests within a category run in order (defined in `_category.yaml`)
- If a test fails: stop -> attempt self-heal -> retry
- Earlier tests can create data for later tests

### 4. Shared Context (`.context/current_run.json`)
- Fresh file created for each test run
- Tests can store/retrieve data (client IDs, meeting IDs, etc.)
- Not persistent between runs

## No Retries for Actions (CRITICAL)

**Do not retry user actions.** Perform every action once, after validating (by waiting on something) that the system is ready to accept the action.

- **Rule**: Wait for a specific condition that indicates readiness (element visible, URL changed, dialog closed, etc.), then perform the action once. If the action fails, the test fails.
- **Do NOT**: Retry clicks, fills, or other user actions in a loop; do not "click again if form didn't open" or "retry More button if detached."
- **Why**: Retries mask timing or readiness bugs. The correct fix is to wait for the right condition before acting, not to retry until something sticks.

## Key Principles

1. **Black-box testing** - Never assume knowledge of vcita's codebase
2. **Exploration-driven** - Discover UI elements by actually browsing
3. **Self-healing** - When tests fail due to UI changes, re-explore and adapt
4. **Audit trail** - All changes logged with timestamps and reasons
5. **Cascade updates** - Keep all three phase files in sync
6. **Reusability** - Common actions go in `_functions/`
7. **DRY (Don't Repeat Yourself)** - Never duplicate logic, always reuse or extract
8. **Real user actions only** - NEVER use direct URLs, API calls, or shortcuts that a normal user wouldn't know
9. **Matter entity agnosticism** - The matter entity name varies by vertical (clients, properties, patients, students, pets, etc.). Tests must not hardcode a single entity label; use regex, positional selectors, or documented alternatives so tests work across verticals.

## Matter Entity Name Agnosticism (CRITICAL)

vcita uses different **matter entity** labels per business vertical. The same concept is called:
- **Properties** (e.g. Home Services, Landscaper)
- **Clients** (e.g. generic / professional services)
- **Patients** (Healthcare)
- **Students** (Education)
- **Pets** (Pet services)
- and others

**Tests must be agnostic to the entity name** so they pass regardless of which vertical (and thus which label) is in use.

### DO:
- Use **regex** for UI text that varies: e.g. `re.compile(r"1 SELECTED OF \d+")` (not `r"1 SELECTED OF \d+ PROPERTIES"`), `re.compile(r"Delete .+\?")` for confirmation dialogs, `re.compile(r".+ deleted")` for success toasts.
- Use **positional or role-based** selectors where the label varies: e.g. sidebar matter list via `.menu-items-group > div:nth-child(4)` instead of `get_by_text("Properties")`.
- Use **menuitem filter with regex** for "Delete &lt;entity&gt;": e.g. `get_by_role("menuitem").filter(has_text=re.compile(r"^Delete ", re.IGNORECASE))`.
- For "Add &lt;entity&gt;" in Quick Actions, use the shared pattern from **`tests/_params`**: `from tests._params import ADD_MATTER_TEXT_REGEX` then `get_by_text(ADD_MATTER_TEXT_REGEX)` (optionally scoped to the Quick actions panel). The list of entity names lives in **`tests/_params/matter_entities.yaml`**; add new verticals there instead of editing multiple tests.
- Document in script.md that a given locator is entity-agnostic and which labels it covers.

### DO NOT:
- Hardcode "Properties", "Clients", "Delete properties?", "Properties deleted", "Add property", "Delete property" (or any single entity label) in locators or assertions when the UI text varies by vertical.
- Assume the sidebar or dialogs will always show one specific entity name.

### Form labels
Form field labels (e.g. "Property address", "Property type") can also vary by vertical. Where exploration shows variation, prefer `get_by_role` with a flexible name, or try multiple labels (regex or fallbacks) and document in script.md.

## Real User Actions Rule (CRITICAL)

Tests must simulate how a real, average user interacts with the application:

### DO:
- Click visible buttons and links
- Fill in form fields
- Navigate using menus and navigation elements
- Use search boxes to find items
- Scroll to find elements
- Wait for pages to load naturally

### DO NOT:
- Navigate directly to URLs (except the initial entry point)
- Use "hidden" URLs like `/users/logout` or `/api/...`
- Assume the user knows URL patterns
- Use browser developer tools actions
- Bypass UI flows with direct navigation
- Use `page.reload()` or `page.refresh()` - Wait for UI to update naturally or navigate via UI

### Why This Matters:
- Tests should catch UI/UX issues a user would encounter
- Direct URL navigation skips important UI paths that might break
- If a button is missing or broken, the test should fail
- Real users don't type URLs - they click buttons

### Example - Logout:
```
WRONG: Navigate to base_url + "/users/logout" (or any direct logout URL)
RIGHT: Click user avatar -> Click "Logout" in dropdown menu
```

### Exception - Entry Points:
The ONLY acceptable direct navigation is to the application's main entry point:
- Login page: **base_url + "/login"** (from config.yaml target.base_url)
- Public pages that users would bookmark or type directly

### Example - Navigating to a specific record:
```
WRONG: page.goto(f"{base_url}/app/clients/{id}")
RIGHT:
  - If running after a test that left browser on that page: verify URL contains the ID
  - If need to navigate there: search for the record name, click it in results
```

### IMPORTANT: Sequential Test Context
Tests in a sequence share browser state. The previous test's end state is the current test's start state. Tests should:
- **Verify** they're starting from the expected state (not navigate to it)
- **FAIL** if the start state is wrong - don't silently "fix" it with navigation
- **Trust** that previous tests leave the browser in the documented end state

Example pattern for sequential tests:
```python
# WRONG - unconditionally navigates
page.goto(f"{base_url}/app/clients/{matter_id}")

# RIGHT - verifies expected state from previous test
if matter_id not in page.url:
    raise ValueError(f"Expected to be on matter page {matter_id}, but URL is {page.url}")
```

## Test Cleanup Rule (CRITICAL)

**Each test category must leave minimal leftover objects when it runs completely.**

### Principle

After a category completes execution (all tests, setup, and teardown), the system should be left in a clean state with minimal test data remaining. This ensures:
- Test data doesn't accumulate across runs
- Tests don't interfere with each other
- The system remains usable for manual testing
- Test runs are reproducible and independent

### Requirements

1. **Objects created in `_setup` must be deleted in `_teardown`**
   - All test data created during setup must be cleaned up
   - Use delete functions or direct deletion steps in teardown
   - Clear context variables after deletion

2. **Objects created in tests must be deleted in subsequent tests or `_teardown`**
   - Follow CRUD pattern: Create → Read/Edit → Delete
   - Delete tests should run after create/edit tests
   - If deletion isn't part of the test flow, use teardown

3. **Objects that cannot be deleted should be cancelled/marked as inactive**
   - Some objects (e.g., appointments) can only be cancelled, not deleted
   - Cancelled objects remaining in system is acceptable (they're inactive)
   - Document this limitation in teardown or delete test

4. **Context variables must be cleared after objects are deleted**
   - Remove context variables when objects are deleted
   - Prevents stale data from affecting future runs

### Verification

Before marking a category complete, verify:
- Run the category end-to-end
- Check that no active test objects remain in the system
- Verify context variables are cleared
- Confirm cancelled/inactive objects are acceptable (documented)

### Cleanup Patterns

**Pattern 1: Delete Test in Sequence**
```
create_service → edit_service → delete_service
```
The delete test removes the object created earlier in the sequence.

**Pattern 2: Teardown Cleanup**
```
_setup (creates service, client)
create_appointment → cancel_appointment
create_custom_appointment → cancel_custom_appointment
_teardown (deletes service, client)
```
Teardown removes objects created in setup. Tests clean up their own objects.

**Pattern 3: Cancellation Instead of Deletion**
```
create_appointment → cancel_appointment (appointment marked as "Cancelled")
create_custom_appointment → cancel_custom_appointment (appointment marked as "Cancelled")
```
Appointments cannot be deleted, only cancelled. Cancelled appointments remaining is acceptable.

### Examples

**✅ GOOD - Complete Cleanup:**
- `clients` category: `create_matter` → `delete_matter` (matter deleted)
- `clients/notes` subcategory: `add_note` → `delete_note` (note deleted)
- `scheduling/services` subcategory: `create_service` → `delete_service`, `create_group_event` → `delete_group_event` (both deleted)
- `scheduling/appointments` subcategory: `create_appointment` → `cancel_appointment`, `create_custom_appointment` → `cancel_custom_appointment` (both cancelled, acceptable)

**❌ BAD - Incomplete Cleanup:**
- Creating objects without deleting them
- Relying on teardown but not having teardown
- Creating objects in tests that are never cleaned up

### Exception Handling

**If an object cannot be deleted:**
- Document why (e.g., "Appointments can only be cancelled, not deleted")
- Ensure it's marked as inactive/cancelled
- Note in teardown or delete test that object remains but is inactive
- This is acceptable cleanup - inactive objects don't interfere with future runs

### Reference

See cleanup analysis in `.cursor/plans/test_cleanup_analysis_and_fixes_*.plan.md` for detailed examples of proper cleanup patterns.

## Function Reuse Rules (CRITICAL)

### Before Creating or Modifying Any Test

1. **ALWAYS scan existing functions first**
   - Read `tests/_functions/_functions.yaml` to see available functions
   - Check if any existing function can achieve the step you need
   - If a function exists, use `Call: function_name` instead of writing new steps

2. **Match by intent, not exact name**
   - "Navigate to CRM" might be covered by `navigate_to_section` with parameter
   - "Fill client form" might be covered by `create_client`
   - Think about what the function DOES, not just its name

### When to Extract a New Function

1. **Duplicate detection** - If you see the same sequence of 2+ steps appearing in:
   - Multiple tests
   - Multiple categories
   - Setup/teardown AND tests
   
   Then EXTRACT it into a new function immediately.

2. **Common patterns to extract**:
   - Navigation sequences (go to specific section)
   - Form filling (create/edit entities)
   - Verification sequences (check something exists)
   - Cleanup actions (delete, reset)

3. **Extraction process**:
   - Create new folder in `tests/_functions/`
   - Move the repeated steps into the function's `steps.md`
   - Update all tests that had this logic to use `Call: new_function`
   - Log the extraction in each affected test's `changelog.md`

### Function Naming Convention

- Use verb_noun format: `create_client`, `navigate_to_calendar`, `verify_booking`
- Be specific: `login` not `authenticate`, `create_meeting` not `add_item`
- Parameters make functions flexible: `navigate_to_section(section_name)` covers many cases

### Example: Detecting Duplication

If you see this in test A:
```
1. Click on CRM menu
2. Click on Clients
3. Click Add New Client
```

And this in test B:
```
1. Go to CRM
2. Open Clients section  
3. Click the Add Client button
```

These are the SAME action - extract to `navigate_to_add_client` function.

## File Locations

- `tests/` - Test categories, tests, and functions
- `tests/_functions/` - Global reusable functions
- `.context/` - Runtime shared context (gitignored)
- `src/` - Source code
- `config.yaml` - Configuration settings
- `tests/{category}/_runs/` - Test run results, screenshots, and videos
- `runs_index/` - Multi-category run index files

## Cursor Rules Files

| Rule File | When to Use |
|-----------|-------------|
| `project.mdc` | Overall architecture and principles (this file) |
| `phase1_steps.mdc` | Writing or editing `steps.md` files |
| `phase2_script.mdc` | Writing or editing `script.md` files |
| `phase3_code.mdc` | Generating or editing `test.py` files |
| `build.mdc` | Building new tests/functions from `steps.md` |
| `heal.mdc` | Fixing failed tests from heal requests |

## When Working on This Project

- **Building new tests**: Follow `build.mdc` - explore with browser, generate script.md and test.py
- **Fixing failures**: Follow `heal.mdc` - analyze heal request, re-explore, update files
- **Editing steps.md**: Follow `phase1_steps.mdc`
- **Editing script.md**: Follow `phase2_script.mdc`
- **Editing test.py**: Follow `phase3_code.mdc`
- Always log changes to `changelog.md`
- Use exploration to discover elements, don't hardcode selectors
- Put reusable actions in `_functions/`, not duplicated in tests

## Request Locations

- `.cursor/heal_requests/` - Heal requests from test runner (failures)
- `.cursor/bug_reports/` - Bug reports (product issues, not test issues)